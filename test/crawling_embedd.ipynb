{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f3b8a3cd-e555-4c62-99e5-9cffac1dcfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Crawling_Dataset import Crawling_Dataset\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import Resize\n",
    "import cv2 \n",
    "import os\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "import torch.utils.data as data\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1, fixed_image_standardization\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be0465dc-1828-4559-a474-30a96c1a5076",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = '/opt/ml/data/celeb_30/cut_test'\n",
    "train_path = '/opt/ml/data/celeb_30/cut_train'\n",
    "BATCH_SIZE = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e20df1fe-8faa-4ab8-a8ba-8728b7fee791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Running on device: {}'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681bf881-9b91-41ba-94b8-6b9da2dd744d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(threshold, dist, actual_issame):\n",
    "    predict_issame = np.less(dist, threshold)\n",
    "    tp = np.sum(np.logical_and(predict_issame, actual_issame))\n",
    "    fp = np.sum(np.logical_and(predict_issame, np.logical_not(actual_issame)))\n",
    "    tn = np.sum(np.logical_and(np.logical_not(predict_issame), np.logical_not(actual_issame)))\n",
    "    fn = np.sum(np.logical_and(np.logical_not(predict_issame), actual_issame))\n",
    "\n",
    "    is_fp = np.logical_and(predict_issame, np.logical_not(actual_issame))\n",
    "    is_fn = np.logical_and(np.logical_not(predict_issame), actual_issame)\n",
    "\n",
    "    tpr = 0 if (tp+fn==0) else float(tp) / float(tp+fn)\n",
    "    fpr = 0 if (fp+tn==0) else float(fp) / float(fp+tn)\n",
    "    acc = float(tp+tn)/dist.size\n",
    "    return tpr, fpr, acc, is_fp, is_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2f17f0f4-241b-4107-bc91-004fca8b5e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "        np.float32,\n",
    "        transforms.ToTensor(),  # range [0, 255] -> [0.0, 1.0]\n",
    "        fixed_image_standardization\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "eb18df88-9229-44c5-a0e9-ff0b08d47229",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Crawling_Dataset(Enrolled_FILE_PATH=train_path, TEST_FILE_PATH=test_path, transforms=transform)\n",
    "embedding_loader =data.DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "09e8faa0-2937-4a3b-b5a2-fcec10b9f0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InceptionResnetV1(\n",
    "    classify=False,\n",
    "    pretrained='vggface2'\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4c8ae94b-9248-40b7-9774-7d57df76a8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('SongJoongki', 'Jojeongseok')\n",
      "0\n",
      "(1, 512)\n",
      "(10, 512)\n",
      "(10, 512)\n",
      "positive distance : \n",
      "[0.42599598 0.34496748 0.52342516 0.27476713 0.4425782  0.5255498\n",
      " 0.41805807 0.35854483 0.2805431  0.5122041 ]\n",
      "negative distance : \n",
      "[1.034279   1.4414062  0.6952398  0.84802854 1.1006616  1.0702555\n",
      " 0.6236588  1.071336   1.0543851  0.8297361 ]\n",
      "1\n",
      "(1, 512)\n",
      "(10, 512)\n",
      "(10, 512)\n",
      "positive distance : \n",
      "[0.33855894 0.32320276 0.25040722 0.48597103 0.32181776 0.39690956\n",
      " 0.2592365  0.20619507 0.39997667 0.4392305 ]\n",
      "negative distance : \n",
      "[0.67458963 1.0547748  0.7404216  0.559502   0.60595524 0.7801169\n",
      " 0.80284184 0.9813439  0.8526923  1.2568748 ]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for enrolled_image, enrolled_label, positive_blocks, negative_blocks in embedding_loader :\n",
    "        print(enrolled_label)\n",
    "        for batch in range(BATCH_SIZE) : \n",
    "            print(batch)\n",
    "            sub_enrolled_image = enrolled_image[batch]\n",
    "            sub_positive_blocks = positive_blocks[batch]\n",
    "            sub_negative_blocks = negative_blocks[batch]\n",
    "            \n",
    "            sub_enrolled_image = sub_enrolled_image.to(device)\n",
    "            sub_positive_blocks = sub_positive_blocks.to(device)\n",
    "            sub_negative_blocks = sub_negative_blocks.to(device)\n",
    "\n",
    "            sub_enrolled_embedding = model(sub_enrolled_image)\n",
    "            sub_positive_blocks_embedding = model(sub_positive_blocks)\n",
    "            sub_negative_blocks_embedding = model(sub_negative_blocks)\n",
    "            sub_enrolled_embedding = sub_enrolled_embedding.to('cpu').numpy()\n",
    "            sub_positive_blocks_embedding = sub_positive_blocks_embedding.to('cpu').numpy()\n",
    "            sub_negative_blocks_embedding = sub_negative_blocks_embedding.to('cpu').numpy()\n",
    "            print(sub_enrolled_embedding.shape)\n",
    "            print(sub_positive_blocks_embedding.shape)\n",
    "            print(sub_negative_blocks_embedding.shape)\n",
    "\n",
    "            p_dis = distance(sub_enrolled_embedding, sub_positive_blocks_embedding)\n",
    "            n_dis = distance(sub_enrolled_embedding, sub_negative_blocks_embedding)\n",
    "            print('positive distance : ',p_dis,sep = '\\n')\n",
    "            print('negative distance : ',n_dis, sep = '\\n')\n",
    "\n",
    "            thresholds = np.arange(0, 4, 0.01)\n",
    "            \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4171a813-b6fa-4607-b749-33f0dfa90609",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(embeddings1, embeddings2, distance_metric=0):\n",
    "    if distance_metric==0:\n",
    "        # Euclidian distance\n",
    "        diff = np.subtract(embeddings1, embeddings2)\n",
    "        dist = np.sum(np.square(diff),1)\n",
    "    elif distance_metric==1:\n",
    "        # Distance based on cosine similarity\n",
    "        dot = np.sum(np.multiply(embeddings1, embeddings2), axis=1)\n",
    "        norm = np.linalg.norm(embeddings1, axis=1) * np.linalg.norm(embeddings2, axis=1)\n",
    "        similarity = dot / norm\n",
    "        dist = np.arccos(similarity) / math.pi\n",
    "    else:\n",
    "        raise 'Undefined distance metric %d' % distance_metric\n",
    "\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb05731-e23e-491b-aa69-3cd6cfd8e56b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
